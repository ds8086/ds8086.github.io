<!doctype html>
<html lang="en">
<head>
    <title>ds8086 | 2025.10.24</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="dnf, linux, reposync">
    <link rel="stylesheet" href="/assets/css/blog.css">
</head>

<body>

<div class="sidebar">
    <a href="/index.html">home</a>
    <a href="/blog/list.html">blog</a>
    <a href="https://github.com/ds8086/" target="_blank">code</a>
    <a href="/about.html">about</a>
</div>

<div class="pagenav">
    <a href="#mirror">mirror</a>
    <a href="#web-server" style="font-size: 12pt;">- web server</a>
    <a href="#config">config</a>
    <a href="#nginx" style="font-size: 12pt;">- nginx</a>
    <a href="#reposync" style="font-size: 12pt;">- reposync</a>
    <a href="#dnf" style="font-size: 12pt;">- dnf</a>
    <a href="#final-thoughts">final thoughts</a>
    <a href="#updates">updates</a>
</div>

<div class="content">
<section>
    <h1>2025.10.24</h1>
    <h2 id="mirror">mirror</h2>
    <p>
        I have mentioned in a <a href="/blog/20250811.html" target="_blank">previous post</a> that Almalinux has become my Linux distro of choice since the death of
        CentOS. With a growing number Almalinux domains running on my home lab box, I have been exploring different options for patching. I do <u>not</u> have an
        unlimited data plan with my ISP and even if I <i>did</i>, it would be irresponsible to download the same patch more than once. I was tinkering with a squid
        proxy for the sake of caching packages which technically works... I've <i>seen</i> it work, but there are caveats in <i>making</i> it work.
    </p>
    <ul>
        <li>HTTPS repositories require squid SSL bump.</li>
        <li>Cached data lifecycle tuning is required.</li>
        <li>If mirrors change, cached data is not hit.</li>
        <ul>
            <li>You may download the same data twice.</li>
            <li>You may cache the same data twice.</li>
        </ul>
    </ul>
    <p>
        Squid is a great solution for a proxy, web cache, and even filtering. There is a better option for managing packages locally; your own mirror.
    </p>
    <h3 id="web-server">web server</h3>
    <p>
        To quote Bob Ross; <i>"It's time to make a big decision."</i> Apache or Nginx? How about a quick look at both options.
    </p>
    <h4>apache</h4>
    <p>
        Tried and true Apache web server; 11 dependencies 3 of which are considered weak. 2MB downloaded and 6.1M installed.
    </p>
    <a href="/assets/images/20251024/01.png"><img src="/assets/images/20251024/01.png"></a>
    <h4>nginx</h4>
    <p>
        The young gun by comparison, Nginx; 3 dependencies <u>none</u> of which are considered weak. Fits on a floppy disk...
    </p>
    <a href="/assets/images/20251024/02.png"><img src="/assets/images/20251024/02.png"></a>
    <p>
        Nginx<b>*</b> is the clear winner and with that, let us begin.
    </p>
    <p>
        <b>*</b> Engine (ˈen-jən) X ('eks)
    </p>
</section>
    
<section>
    <h2 id="config">config</h2>
    <p>
        To start, two packages need to be installed on server which will act as a local repo mirror.
    </p>
    <pre>
        <code>
dnf install nginx yum-utils -y
        </code>
    </pre>
    <h3 id="nginx">nginx</h3>
    <p>
        The code below will create the folder structure for the repo files and set required permissions.
    </p>
    <pre>
        <code>
mkdir -p /var/www/repos/almalinux/9/x86_64/os
chmod -R 755 /var/www/repos
        </code>
    </pre>
    <p>
        A basic nginx config can be created at <b>/etc/nginx/conf.d/repo.conf</b> with the content below.
    </p>
    <pre>
        <code>
include /etc/nginx/conf.d/*.conf;

server {
    # listen on port 80
    listen 80;

    # server name
    server_name mirror.ds.lan;

    # default location
    location / {
    
      # root directory
      root /var/www/repos;
      autoindex on;

    }
}
        </code>
    </pre>
    <p>
        The server needs a firewall rule to allow HTTP.
    </p>
    <pre>
        <code>
firewall-cmd --add-service=http --permanent
firewall-cmd --reload
        </code>
    </pre>
    <p>
        Finally, nginx can be started.
    </p>
    <pre>
        <code>
systemctl enable --now nginx
        </code>
    </pre>
    <p>
        Accessing the website via browser confirms nginx is running and the directory structure can be navigated.
    </p>
    <a href="/assets/images/20251024/03.png"><img src="/assets/images/20251024/03.png"></a>
    <h3 id="reposync">reposync</h3>
    <p>
        With Nginx configured and confirmed working, the <b>reposync</b> command included with <b>yum-utils</b> is for repository synchronization. How intuitive!
        Not very on-brand for Linux, eh? You will notice that I am only syncing the baseos repo, and not the appstream nor extras repos. Why?...
    </p>
    <pre>
        <code>
reposync -p /var/www/repos/almalinux/9/x86_64/os --repo=baseos --download-metadata --newest-only
        </code>
    </pre>
    <p>
        ...Mainly because I have yet to find a way to explicitly <u>include</u> only packages and dependencies that I care about during sync. The <b>reposync</b> command
        has an <b>--exclude</b> option, but that achieves the exact opposite of what I need. Currently, there are around 40 packages in the appstream repo required
        by my environment. I see no reason to sync the <i>entire</i> repo for such a limited number and depending on update frequency and package size,
        I could easily end up using <i>more</i> bandwidth than I save. Devising a solution for syncing the appstream and extras repos will be a "phase 2" effort, depending
        on the complexity level of sorting that out, I will either update this post in the future, or make a post dedicated to the topic.
    </p>
    <p>
        Wrapping up the <b>reposync</b> config, a new crontab can be created with the line below. This will sync the repo each day at 03:00.
    </p>
    <pre>
        <code>
00 3 * * * reposync -p /var/www/repos/almalinux/9/x86_64/os --repo=baseos --download-metadata --newest-only
        </code>
    </pre>    
    <h3 id="dnf">dnf</h3>
    <p>
        Last step, configuring <b>dnf</b> to actually <i>use</i> the newly minted local mirror. Edit <b>/etc/yum.repos.d/almalinux-baseos.repo</b> adding the content
        below to the top of the config. Leave the existing <b>[baseos]</b> repo in place.
    </p>
    <pre>
        <code>
# local mirror
[baseos]
name=AlmaLinux $releasever - BaseOS
baseurl=http://mirror.ds.lan/almalinux/$releasever/x86_64/os/baseos
enabled=1
gpgcheck=1
priority=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-AlmaLinux-9
metadata_expire=86400
enabled_metadata=1
        </code>
    </pre>
    <p>
        The local mirror repo is configured with a priority of 1 which takes precedence over the default baseos repo that ships with Almalinux, which has the default
        priority of 99. I added the local mirror repo to another Almalinux server in my environment for testing. I used <b>dnf clean</b> to purge metadata, forcing
        the test server to re-pull update metadata and re-check for updates. The attempt in green is with Nginx running on the local mirror, while the attempt
        in yellow shows output with nginx stopped on the local mirror to simulate a failure.
    </p>
    <a href="/assets/images/20251024/04.png"><img src="/assets/images/20251024/04.png"></a>
    <p>
        You can also <b>tail /var/log/nginx/access.log</b> to both verify that requests are indeed hitting the local mirror <u>and</u> that <b>200</b> responses are being
        served.
    </p>
    <a href="/assets/images/20251024/05.png"><img src="/assets/images/20251024/05.png"></a>
</section>

<section>
    <h2 id="final-thoughts">final thoughts</h2>
    <p>
        If you have standardized on a single Linux distro for your lab environment and you have more than a few machines, creating a local mirror is such an easy win.
        In a production environment where you do not have a data limit, adding the lines to your <b>crontab</b> gets you the appstream and extras repos as well.
    </p>
    <pre>
        <code>
reposync -p /var/www/repos/almalinux/9/x86_64/os --repo=appstream --download-metadata --newest-only
reposync -p /var/www/repos/almalinux/9/x86_64/os --repo=extras --download-metadata --newest-only
        </code>
    </pre>
    <p>
        <i>"Wait! What happens when a package is synced down that breaks input in the Linux recovery environment?"</i>
    </p>
    <p>
        First off, you are thinking of Microsoft... but once Almalinux pulls the update and the upstream mirror you pull from reflects that change, you would run
        a sync including the <b>--delete</b> flag to remove local repo packages which no longer exist in the remote repo. You could even do <i>this</i> on a schedule
        as a housekeeping routine.
    </p>
</section>

<div class="footer">
    <a href="/blog/20251029.html">◄-2025.10.29</a><b>...</b><a href="/blog/20251020.html">2025.10.20-►</a>
</div>

</div>
</body>
</html>